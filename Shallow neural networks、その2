ニューラルネットワークを設計するとき、隠す層の神経細胞の数、活性化関数の選択または初期値...などなど、
最初から決まったわけではありません。
応用場面から、直感的な結果によって選びます。
もしくは特徴があるニューラルネットワークがあれば、たくさん選んで試行錯誤をしながら、決めましょう。

■活性化関数

ニューラルネットワークを使うとき、隠れ層にはどちらの活性化関数を適用するか、出力層にはどちらの
活性化関数を適用するか、は決めないといけません。
異なる層には活性化関数が異なるのはあり得ます。

・sigmoid　⇒（0,1）、二項分類の出力層に最適
・tanh　⇒（-1,1）、平均値は0に近づき、データを中心化にした方がいい
・ReLU　⇒max（0, z）、優先択

■Weight値は0ではなく、（0～1）ランダムにさせる

